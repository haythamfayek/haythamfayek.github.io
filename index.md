---
layout: page
title: Haytham Fayek
---

<p><img src="/assets/Haytham.jpg" alt="Haytham" class="profilepicmain"/></p>

Artificial Intelligence, Machine Learning, & Deep Learning Researcher.  
Vice-Chancellor PhD Candidate, [RMIT University](https://www.rmit.edu.au).  
Ex-Intern Oculus / Facebook, & WorleyParsons. Ex-Engineer AGI.  
[About](about)  |  [Resume](assets/Fayek_resume.pdf) |  [Twitter](https://twitter.com/HaythamFayek)  |  [LinkedIn](https://www.linkedin.com/in/haythamfayek/)  |  [Github](https://github.com/haythamfayek).

<br/>

---

<br/>

## Updates

**Feb 2018**: Teaching Assistant at RMIT for Postgraduate COSC1295 Advanced Programming and Undergraduate EEET2169 Image Processing.  
**Dec 2017**: At NIPS'17, Long Beach.  
**Nov 2017**: New paper: [MatDL: A lightweight deep learning library in MATLAB](https://doi.org/10.21105/joss.00413) in JOSS.  
**Nov 2017**: At World Youth Forum (WYF'17), Sharm El Sheikh.  
**Oct 2017**: Paper presentation at AES'17, New York on [HRTF Personalization](http://www.aes.org/e-lib/browse.cfm?elib=19287).  
**Sep 2017**: Talk at Swinburne University, Melbourne on Will Deep Learning Lead to AI?.  
**Aug 2017**: Talk at the [ML / AI Melbourne Meetup](https://www.meetup.com/Machine-Learning-AI-Meetup/events/239993347/) on [Will Deep Learning Lead to AI?](../assets/presentations/Fayek_deeplearningai17.pdf).  
**Aug 2017**: At ICML'17, Sydney and IJCAI'17, Melbourne.  

<br/>

---

<br/>

## Research

My research interests are in Artificial Intelligence and Machine Learning.  
[Publications](publications)  |  [Presentations](presentations)  |  [Google Scholar](https://scholar.google.com/citations?user=l5T9RtcAAAAJ&hl=en&authuser=1)  |  [ORCID](https://orcid.org/0000-0002-1840-7605)  

#### Selected Research:
<br/>

<div class="projectleft"><img src="/assets/projects/HRTF.png" alt="Haytham" class="projectpic"/></div>
<div class="projectright" markdown="1">
**On Data-Driven Approaches to Head-Related Transfer Function Personalization.**  
Haytham M. Fayek, Laurens van der Maaten, Griffin D. Romigh, Ravish Mehra.  
Audio Engineering Society Convention 143, New York, USA, Oct 2017.  

*We study the head-related transfer function personalization problem, establish strong baselines, and demonstrate the weaknesses of prior methods compared to the established baselines.*  

<a onclick="toggleShow('Toggled1')">Abstract&#x21D5;</a>
[[ url ]](http://www.aes.org/e-lib/browse.cfm?elib=19287)
[[ bib ]](../assets/bibtex/Fayek_aes17.bib)
</div>
<div id="Toggled1" style="display: none;">
Head-Related Transfer Function (HRTF) personalization is key to improving spatial audio perception and localization in virtual auditory displays. We investigate the task of personalizing HRTFs from anthropometric measurements, which can be decomposed into two sub tasks: Interaural Time Delay (ITD) prediction and HRTF magnitude spectrum prediction. We explore both problems using state-of-the-art Machine Learning (ML) techniques. Firstly, we show that ITD prediction can be significantly improved by smoothing the ITD using a spherical harmonics representation. Secondly, our results indicate that prior unsupervised dimensionality reduction-based approaches may be unsuitable for HRTF personalization. Lastly, we show that neural network models trained on the full HRTF representation improve HRTF prediction compared to prior methods.
</div>
<div style="clear:both"></div>

<br/>

<div class="projectleft"><img src="/assets/projects/SER.jpg" alt="Haytham" class="projectpic"/></div>
<div class="projectright" markdown="1">
**Evaluating deep learning architectures for Speech Emotion Recognition.**  
Haytham M. Fayek, Margaret Lech, and Lawrence Cavedon.  
Neural Networks, vol. 92, pp. 60-68, Aug 2017.  

*A real-time frame-based formulation to speech emotion recognition that relies on minimal speech processing and end-to-end deep learning. We use the proposed system to study various deep learning architectures and report state-of-the-art results on a popular dataset.*

<a onclick="toggleShow('Toggled2')">Abstract&#x21D5;</a>
[[ url ]](http://doi.org/10.1016/j.neunet.2017.02.013)
[[ bib ]](../assets/bibtex/Fayek_nn17.bib)
</div>
<div id="Toggled2" style="display: none;">
Speech Emotion Recognition (SER) can be regarded as a static or dynamic classification problem, which makes SER an excellent test bed for investigating and comparing various deep learning architectures. We describe a frame-based formulation to SER that relies on minimal speech processing and end-to-end deep learning to model intra-utterance dynamics. We use the proposed SER system to empirically explore feed-forward and recurrent neural network architectures and their variants. Experiments conducted illuminate the advantages and limitations of these architectures in paralinguistic speech recognition and emotion recognition in particular. As a result of our exploration, we report state-of-the-art results on the IEMOCAP database for speaker-independent SER and present quantitative and qualitative assessments of the models’ performances.
</div>
<div style="clear:both"></div>

<br/>

<div class="projectleft"><img src="/assets/projects/TL.png" alt="Haytham" class="projectpic"/></div>
<div class="projectright" markdown="1">
**On the correlation and transferability of features between automatic speech recognition and speech emotion recognition.**  
Haytham M. Fayek, Margaret Lech, and Lawrence Cavedon.  
Interspeech, San Francisco, USA, Sep 2016, pp. 3618-3622.  

*We investigate the inter-task information propagation and layer-wise features relevance in deep networks.*

<a onclick="toggleShow('Toggled3')">Abstract&#x21D5;</a>
[[ pdf ]](http://www.isca-speech.org/archive/Interspeech_2016/pdfs/0868.PDF)
[[ url ]](http://www.isca-speech.org/archive/Interspeech_2016/abstracts/0868.html)
[[ slides ]](../assets/presentations/Fayek_is16.pdf)
[[ bib ]](../assets/bibtex/Fayek_is16.bib)
</div>
<div id="Toggled3" style="display: none;">
The correlation between Automatic Speech Recognition (ASR) and Speech Emotion Recognition (SER) is poorly understood. Studying such correlation may pave the way for integrating both tasks into a single system or may provide insights that can aid in advancing both systems such as improving ASR in dealing with emotional speech or embedding linguistic input into SER. In this paper, we quantify the relation between ASR and SER by studying the relevance of features learned between both tasks in deep convolutional neural networks using transfer learning. Experiments are conducted using the TIMIT and IEMOCAP databases. Results reveal an intriguing correlation between both tasks, where features learned in some layers particularly towards initial layers of the network for either task were found to be applicable to the other task with varying degree.
</div>
<div style="clear:both"></div>

<br/>

<div class="projectleft"><img src="/assets/projects/robot.jpg" alt="Haytham" class="projectpic"/></div>
<div class="projectright" markdown="1">
**A controller based on optimal type-2 fuzzy logic: Systematic design, optimization and real-time implementation.**  
Haytham M. Fayek, Irraivan Elamvazuthi, N. Perumal, and Bala Venkatesh.  
ISA Transactions, vol. 53(5), pp. 1583-1591, Sep 2014.  

*We develop a robust controller using Type-2 Fuzzy Logic optimally designed via Particle Swarm Optimization (PSO) and Genetic Algorithm (GA) and demonstrate its efficacy on a robotic arm.*

<a onclick="toggleShow('Toggled4')">Abstract&#x21D5;</a>
[[ url ]](http://doi.org/10.1016/j.isatra.2014.06.001)
[[ bib ]](../assets/bibtex/Fayek_isa14.bib)
</div>
<div id="Toggled4" style="display: none;">
A computationally-efficient systematic procedure to design an Optimal Type-2 Fuzzy Logic Controller (OT2FLC) is proposed. The main scheme is to optimize the gains of the controller using Particle Swarm Optimization (PSO), then optimize only two parameters per type-2 membership function using Genetic Algorithm (GA). The proposed OT2FLC was implemented in real-time to control the position of a DC servomotor, which is part of a robotic arm. The performance judgments were carried out based on the Integral Absolute Error (IAE), as well as the computational cost. Various type-2 defuzzification methods were investigated in real-time. A comparative analysis with an Optimal Type-1 Fuzzy Logic Controller (OT1FLC) and a PI controller, demonstrated OT2FLC׳s superiority; which is evident in handling uncertainty and imprecision induced in the system by means of noise and disturbances.
</div>
<div style="clear:both"></div>

<script type="text/javascript">
function toggleShow(y) {
    var x = document.getElementById(y);
    if (x.style.display === "none") {
        x.style.display = "block";
    } else {
        x.style.display = "none";
    }
}
</script>
